{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDELa7o5UXrY"
      },
      "source": [
        "# DX 704 Week 1 Project\n",
        "\n",
        "This week's project will build a portfolio risk and return model, and make investing recommendations for hypothetical clients.\n",
        "You will collect historical data, estimate returns and risks, construct efficient frontier portfolios, and sanity check the certainty of the maximum return portfolio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6SxppNu8p8k"
      },
      "source": [
        "The full project description and a template notebook are available on GitHub at the following link.\n",
        "\n",
        "https://github.com/bu-cds-dx704/dx704-project-01\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmIaQcdCwObV"
      },
      "source": [
        "Feel free to use optimization tools or libraries (such as CVXOPT or scipy.optimize) to perform any calculations required for this mini project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv3PslO0V5Lm"
      },
      "source": [
        "## Part 1: Collect Data\n",
        "\n",
        "Collect historical monthly price data for the last 24 months covering 6 different stocks.\n",
        "The data should cover 24 consecutive months including the last month that ended before this week's material was released on Blackboard.\n",
        "To be clear, if a month ends between the Blackboard release and submitting your project, you do not need to add that month.\n",
        "\n",
        "The six different stocks must include AAPL, SPY and TSLA.\n",
        "At least one of the remaining 3 tickers must start with the same letter as your last name (e.g. professor Considine could use COIN).\n",
        "This is to encourage diversity in what stocks you analyze; if you discuss this project with classmates, please make sure that you pick different tickers to differentiate your work.\n",
        "Do not pick stocks with fewer than 24 consecutive months of price data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yfinance in /opt/conda/lib/python3.12/site-packages (0.2.65)\n",
            "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.3.1)\n",
            "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (2.3.1)\n",
            "Requirement already satisfied: requests>=2.31 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /opt/conda/lib/python3.12/site-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /opt/conda/lib/python3.12/site-packages (from yfinance) (2.4.2)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /opt/conda/lib/python3.12/site-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /opt/conda/lib/python3.12/site-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from yfinance) (6.32.0)\n",
            "Requirement already satisfied: websockets>=13.0 in /opt/conda/lib/python3.12/site-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /home/codespace/.local/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (2025.7.9)\n",
            "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install yfinance pandas numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6pL-ppubxfvC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/historical_prices.tsv\n",
            "Ticker            AAPL         SPY        TSLA        AMZN        MSFT  \\\n",
            "date                                                                     \n",
            "2025-04-30  211.981125  552.905457  282.160004  184.419998  393.888184   \n",
            "2025-05-31  200.622314  587.652771  346.459991  205.009995  459.604431   \n",
            "2025-06-30  204.937408  617.849976  317.660004  219.389999  496.593658   \n",
            "2025-07-31  207.334702  632.080017  308.269989  234.110001  532.624390   \n",
            "2025-08-31  232.139999  645.049988  333.869995  229.000000  506.690002   \n",
            "\n",
            "Ticker            NVDA  \n",
            "date                    \n",
            "2025-04-30  108.912437  \n",
            "2025-05-31  135.120621  \n",
            "2025-06-30  157.990005  \n",
            "2025-07-31  177.869995  \n",
            "2025-08-31  174.179993  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_7564/1981105712.py:80: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  monthly = prices.groupby(pd.Grouper(freq='M')).last().loc[START_MONTH:END_MONTH]\n"
          ]
        }
      ],
      "source": [
        "# part01_collect_data.py  (robust, uses auto-adjusted Close)\n",
        "# Requirements: pip install yfinance pandas numpy\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# ---- Settings ----\n",
        "TICKERS = ['AAPL', 'SPY', 'TSLA', 'AMZN', 'MSFT', 'NVDA']  # includes A* (AMZN) for \"Asad\"\n",
        "START_MONTH = '2023-09-01'      # 24 months total\n",
        "END_MONTH   = '2025-08-31'      # last full month before Week 1 release\n",
        "OUT_FILE = 'historical_prices.tsv'  # per spec\n",
        "\n",
        "# Optional CSV fallback (if offline): map ticker -> CSV path with columns ['Date','Adj Close' or 'Close']\n",
        "CSV_PATHS = {\n",
        "    # 'AAPL': '/path/to/AAPL.csv',\n",
        "    # 'SPY':  '/path/to/SPY.csv',\n",
        "    # ...\n",
        "}\n",
        "\n",
        "def download_adjusted_close(ticker, start, end_plus):\n",
        "    \"\"\"Return a Series of *adjusted* closes indexed by date.\n",
        "       We use auto_adjust=True so 'Close' is already adjusted.\"\"\"\n",
        "    import yfinance as yf\n",
        "    df = yf.download(\n",
        "        ticker, start=start, end=end_plus,\n",
        "        progress=False, auto_adjust=True, actions=False, group_by='column'\n",
        "    )\n",
        "    if df.empty:\n",
        "        raise ValueError(f\"No data returned for {ticker}\")\n",
        "    # With auto_adjust=True, 'Close' is adjusted close\n",
        "    if 'Close' not in df.columns:\n",
        "        raise KeyError(f\"'Close' not found for {ticker}; columns: {list(df.columns)}\")\n",
        "    s = df['Close'].copy()\n",
        "    s.name = ticker\n",
        "    return s\n",
        "\n",
        "def load_from_csvs():\n",
        "    frames = []\n",
        "    for t in TICKERS:\n",
        "        path = CSV_PATHS.get(t)\n",
        "        if not path or not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"CSV for {t} not found. Set CSV_PATHS['{t}'] to your file.\")\n",
        "        raw = pd.read_csv(path)\n",
        "        if 'Date' not in raw.columns:\n",
        "            raise ValueError(f\"{t} CSV must have a 'Date' column.\")\n",
        "        # Prefer 'Adj Close'; else fall back to 'Close'\n",
        "        col = 'Adj Close' if 'Adj Close' in raw.columns else 'Close' if 'Close' in raw.columns else None\n",
        "        if not col:\n",
        "            raise ValueError(f\"{t} CSV must have 'Adj Close' or 'Close' column.\")\n",
        "        raw['Date'] = pd.to_datetime(raw['Date'])\n",
        "        raw = raw.set_index('Date').sort_index()\n",
        "        frames.append(raw[[col]].rename(columns={col: t}))\n",
        "    prices = pd.concat(frames, axis=1).sort_index().ffill()\n",
        "    return prices\n",
        "\n",
        "def main():\n",
        "    # Try yfinance first; if not available or fails, use CSV fallback\n",
        "    use_csv = False\n",
        "    try:\n",
        "        import yfinance  # noqa: F401\n",
        "    except Exception:\n",
        "        use_csv = True\n",
        "\n",
        "    if not use_csv:\n",
        "        try:\n",
        "            end_plus = pd.to_datetime(END_MONTH) + pd.Timedelta(days=2)  # cushion to include last trading day\n",
        "            series = []\n",
        "            for t in TICKERS:\n",
        "                s = download_adjusted_close(t, START_MONTH, end_plus)\n",
        "                series.append(s)\n",
        "            prices = pd.concat(series, axis=1).sort_index().ffill()\n",
        "        except Exception as e:\n",
        "            print(\"yfinance path failed:\", e)\n",
        "            print(\"Falling back to CSV files specified in CSV_PATHS...\")\n",
        "            use_csv = True\n",
        "\n",
        "    if use_csv:\n",
        "        prices = load_from_csvs()\n",
        "\n",
        "    # Collapse to last trading day of each month\n",
        "    monthly = prices.groupby(pd.Grouper(freq='M')).last().loc[START_MONTH:END_MONTH]\n",
        "    monthly.index.name = 'date'\n",
        "\n",
        "    # Sanity checks\n",
        "    if monthly.shape[0] != 24:\n",
        "        print(f\"Warning: expected 24 monthly rows, got {monthly.shape[0]}. Check START/END.\")\n",
        "    missing = [t for t in TICKERS if t not in monthly.columns]\n",
        "    if missing:\n",
        "        print(f\"Warning: missing columns: {missing}\")\n",
        "\n",
        "    # Save TSV: date + 6 tickers (adjusted closes)\n",
        "    monthly.reset_index().to_csv(OUT_FILE, sep='\\t', index=False)\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(monthly.tail())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uH9oDQ1rEQT"
      },
      "source": [
        "Save the data as a TSV file named \"historical_prices.tsv\" and include a header row with the column names \"date\" and the 6 stock ticker symbols.\n",
        "The date should be the last trading day of the month, so it may not be the last day of the month.\n",
        "For example, the last trading day of November 2024 was 2024-11-29.\n",
        "The remaining columns should contain the adjusted closing prices of the corresponding stock tickers on that day.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "mHbwKHOhtQ3E"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/historical_prices.tsv\n",
            "Tail preview:\n",
            "Ticker            AAPL         SPY        TSLA        AMZN        MSFT  \\\n",
            "date                                                                     \n",
            "2025-04-30  211.981125  552.905457  282.160004  184.419998  393.888184   \n",
            "2025-05-31  200.622314  587.652771  346.459991  205.009995  459.604431   \n",
            "2025-06-30  204.937408  617.849976  317.660004  219.389999  496.593658   \n",
            "2025-07-31  207.334702  632.080017  308.269989  234.110001  532.624390   \n",
            "2025-08-31  232.139999  645.049988  333.869995  229.000000  506.690002   \n",
            "\n",
            "Ticker            NVDA  \n",
            "date                    \n",
            "2025-04-30  108.912437  \n",
            "2025-05-31  135.120621  \n",
            "2025-06-30  157.990005  \n",
            "2025-07-31  177.869995  \n",
            "2025-08-31  174.179993  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_7564/1125391832.py:43: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
            "  monthly = prices.groupby(pd.Grouper(freq='M')).last().loc[START_MONTH:END_MONTH]\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Part 1 — Collect Data → historical_prices.tsv\n",
        "# Uses adjusted prices and collapses to the last trading day of each month.\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# ---- Settings (edit only if your section uses different cutoff/tickers) ----\n",
        "TICKERS = ['AAPL', 'SPY', 'TSLA', 'AMZN', 'MSFT', 'NVDA']  # includes A* (AMZN) for \"Asad\"\n",
        "START_MONTH = '2023-09-01'   # 24 months total\n",
        "END_MONTH   = '2025-08-31'   # last full month before Week 1 release\n",
        "OUT_FILE = 'historical_prices.tsv'  # per spec\n",
        "\n",
        "def download_adjusted_close(ticker, start, end_plus):\n",
        "    \"\"\"\n",
        "    Returns a Series of *adjusted* closes indexed by date.\n",
        "    auto_adjust=True -> 'Close' is already adjusted for splits/dividends.\n",
        "    \"\"\"\n",
        "    import yfinance as yf\n",
        "    df = yf.download(\n",
        "        ticker, start=start, end=end_plus,\n",
        "        auto_adjust=True, actions=False, progress=False, group_by='column'\n",
        "    )\n",
        "    if df.empty:\n",
        "        raise ValueError(f\"No data returned for {ticker}\")\n",
        "    if 'Close' not in df.columns:\n",
        "        raise KeyError(f\"'Close' not found for {ticker}; columns: {list(df.columns)}\")\n",
        "    s = df['Close'].copy()\n",
        "    s.name = ticker\n",
        "    return s\n",
        "\n",
        "# 1) Download daily adjusted closes for each ticker and align\n",
        "end_plus = pd.to_datetime(END_MONTH) + pd.Timedelta(days=2)  # cushion so last trading day is included\n",
        "series = []\n",
        "for t in TICKERS:\n",
        "    s = download_adjusted_close(t, START_MONTH, end_plus)\n",
        "    series.append(s)\n",
        "\n",
        "prices = pd.concat(series, axis=1).sort_index().ffill()\n",
        "\n",
        "# 2) Collapse to the *last trading day* of each month (not necessarily last calendar day)\n",
        "monthly = prices.groupby(pd.Grouper(freq='M')).last().loc[START_MONTH:END_MONTH]\n",
        "monthly.index.name = 'date'\n",
        "\n",
        "# 3) Optional sanity checks\n",
        "if monthly.shape[0] != 24:\n",
        "    print(f\"Warning: expected 24 monthly rows, got {monthly.shape[0]}. Check START/END.\")\n",
        "missing = [t for t in TICKERS if t not in monthly.columns]\n",
        "if missing:\n",
        "    print(f\"Warning: missing columns: {missing}\")\n",
        "\n",
        "# 4) Save TSV with header: date + tickers (values = adjusted closes)\n",
        "monthly.reset_index().to_csv(OUT_FILE, sep='\\t', index=False)\n",
        "\n",
        "print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "print(\"Tail preview:\")\n",
        "print(monthly.tail())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hp0yuXPtT9V"
      },
      "source": [
        "Submit \"historical_prices.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XdNVWWirUd5"
      },
      "source": [
        "## Part 2: Calculate Historical Asset Returns\n",
        "\n",
        "Calculate the historical asset returns based on the price data that you previously collected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "aL-kVua2xex-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/historical_returns.tsv\n",
            "Preview:\n",
            "                AAPL       SPY      TSLA      AMZN      MSFT      NVDA\n",
            "date                                                                  \n",
            "2023-10-31 -0.002570 -0.021709 -0.197346  0.046963  0.070815 -0.062507\n",
            "2023-11-30  0.113780  0.091344  0.195379  0.097678  0.122946  0.146886\n",
            "2023-12-31  0.013582  0.045656  0.034988  0.040044 -0.007574  0.058934\n",
            "2024-01-31 -0.042227  0.015926 -0.246257  0.021456  0.057281  0.242418\n",
            "2024-02-29 -0.018543  0.052187  0.077901  0.138918  0.042318  0.285810\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part02_returns.py\n",
        "# Calculates simple monthly returns from historical_prices.tsv\n",
        "# Output: historical_returns.tsv (date + 6 tickers, 23 rows)\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "IN_FILE  = 'historical_prices.tsv'\n",
        "OUT_FILE = 'historical_returns.tsv'\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(IN_FILE):\n",
        "        raise FileNotFoundError(\n",
        "            f\"Could not find {IN_FILE}. Run Part 1 first to create it.\"\n",
        "        )\n",
        "\n",
        "    # 1) Load prices (date is last trading day per month)\n",
        "    prices = pd.read_csv(IN_FILE, sep='\\t', parse_dates=['date']).set_index('date').sort_index()\n",
        "\n",
        "    # 2) Simple returns: (P_t - P_{t-1}) / P_{t-1}\n",
        "    returns = prices.pct_change().dropna(how='any')  # 24 prices → 23 returns\n",
        "\n",
        "    # 3) Optional sanity checks\n",
        "    if returns.shape[0] != 23:\n",
        "        print(f\"Warning: expected 23 monthly return rows, got {returns.shape[0]}.\")\n",
        "    if list(returns.columns) != list(prices.columns):\n",
        "        print(\"Warning: column order changed.\")\n",
        "\n",
        "    # 4) Save TSV with header: date + tickers (values are relative returns, e.g., 0.10 for +10%)\n",
        "    returns.reset_index().to_csv(OUT_FILE, sep='\\t', index=False)\n",
        "\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(\"Preview:\")\n",
        "    print(returns.head())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjhEYCWOrIu3"
      },
      "source": [
        "Save the data as a TSV file named \"historical_returns.tsv\" and include a header row with the column names \"date\" and the 6 stock ticker symbols.\n",
        "Each row should have the date at the end of the month and the corresponding *relative* price changes.\n",
        "For example, if the previous price was \\$100 and the new price is \\$110, the return value should be 0.10.\n",
        "There should only be 23 rows of data in this file, since they are computed as the differences of 24 prices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cN-7q9QvvyKG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/historical_returns.tsv\n",
            "Preview:\n",
            "                AAPL       SPY      TSLA      AMZN      MSFT      NVDA\n",
            "date                                                                  \n",
            "2023-10-31 -0.002570 -0.021709 -0.197346  0.046963  0.070815 -0.062507\n",
            "2023-11-30  0.113780  0.091344  0.195379  0.097678  0.122946  0.146886\n",
            "2023-12-31  0.013582  0.045656  0.034988  0.040044 -0.007574  0.058934\n",
            "2024-01-31 -0.042227  0.015926 -0.246257  0.021456  0.057281  0.242418\n",
            "2024-02-29 -0.018543  0.052187  0.077901  0.138918  0.042318  0.285810\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part02_returns.py\n",
        "# Computes simple monthly returns from historical_prices.tsv\n",
        "# Output: historical_returns.tsv (date + 6 tickers, exactly 23 rows)\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "IN_FILE  = \"historical_prices.tsv\"\n",
        "OUT_FILE = \"historical_returns.tsv\"\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(IN_FILE):\n",
        "        raise FileNotFoundError(f\"{IN_FILE} not found. Run Part 1 first.\")\n",
        "\n",
        "    # 1) Load monthly prices (already last trading day per month)\n",
        "    prices = pd.read_csv(IN_FILE, sep=\"\\t\", parse_dates=[\"date\"]).set_index(\"date\").sort_index()\n",
        "\n",
        "    # 2) Simple relative returns: (P_t - P_{t-1}) / P_{t-1}\n",
        "    returns = prices.pct_change().dropna(how=\"any\")  # 24 prices → 23 returns\n",
        "\n",
        "    # 3) Sanity checks\n",
        "    if returns.shape[0] != 23:\n",
        "        print(f\"Warning: expected 23 rows of returns, got {returns.shape[0]}. Check Part 1 window.\")\n",
        "    if \"date\" in returns.columns:\n",
        "        # Make sure 'date' is the index only\n",
        "        returns = returns.drop(columns=[\"date\"])\n",
        "\n",
        "    # 4) Save as TSV with header: date + 6 ticker symbols\n",
        "    returns.reset_index().to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(\"Preview:\")\n",
        "    print(returns.head())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyBtnCTUtfRq"
      },
      "source": [
        "Submit \"historical_returns.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoCkf4ouV9IA"
      },
      "source": [
        "## Part 3: Estimate Returns\n",
        "\n",
        "Estimate the expected returns for each asset using the previously calculated return data.\n",
        "Just compute the average (mean) return for each asset over your data set; do not use other estimators that have been mentioned.\n",
        "This will serve as your estimate of expected return for each asset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "N2iDEhSRxd2n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/estimated_returns.tsv\n",
            "  asset  estimated_return\n",
            "5  NVDA          0.068636\n",
            "3  AMZN          0.028061\n",
            "2  TSLA          0.025313\n",
            "4  MSFT          0.023318\n",
            "1   SPY          0.019666\n",
            "0  AAPL          0.015442\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part03_estimate_returns.py\n",
        "# Input : historical_returns.tsv  (date + 6 tickers, 23 rows)\n",
        "# Output: estimated_returns.tsv   (asset, estimated_return)\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "IN_FILE  = \"historical_returns.tsv\"\n",
        "OUT_FILE = \"estimated_returns.tsv\"\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(IN_FILE):\n",
        "        raise FileNotFoundError(f\"{IN_FILE} not found. Run Part 2 first.\")\n",
        "\n",
        "    # 1) Load monthly returns\n",
        "    df = pd.read_csv(IN_FILE, sep=\"\\t\", parse_dates=[\"date\"])\n",
        "\n",
        "    # 2) Identify asset columns (everything except 'date')\n",
        "    assets = [c for c in df.columns if c != \"date\"]\n",
        "    if len(assets) != 6:\n",
        "        print(f\"Warning: expected 6 assets, found {len(assets)}: {assets}\")\n",
        "\n",
        "    # 3) Compute expected returns (simple mean across 23 months)\n",
        "    mu = df[assets].mean()\n",
        "\n",
        "    # 4) Save as TSV: asset, estimated_return (preserve asset order from file)\n",
        "    out = pd.DataFrame({\"asset\": assets, \"estimated_return\": [mu[a] for a in assets]})\n",
        "    out.to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(out.sort_values(\"estimated_return\", ascending=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5YTEwoarM2M"
      },
      "source": [
        "Save the estimated returns in a TSV file named \"estimated_returns.tsv\" and include a header row with the column names \"asset\" and \"estimated_return\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "At71YDpwvwUw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/estimated_returns.tsv\n",
            "  asset  estimated_return\n",
            "0  AAPL          0.015442\n",
            "1   SPY          0.019666\n",
            "2  TSLA          0.025313\n",
            "3  AMZN          0.028061\n",
            "4  MSFT          0.023318\n",
            "5  NVDA          0.068636\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part03_estimate_returns.py\n",
        "# Input : historical_returns.tsv  (date + 6 tickers, 23 rows)\n",
        "# Output: estimated_returns.tsv   (asset, estimated_return)\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "IN_FILE  = \"historical_returns.tsv\"\n",
        "OUT_FILE = \"estimated_returns.tsv\"\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(IN_FILE):\n",
        "        raise FileNotFoundError(f\"{IN_FILE} not found. Run Part 2 first.\")\n",
        "\n",
        "    # Load monthly returns\n",
        "    df = pd.read_csv(IN_FILE, sep=\"\\t\", parse_dates=[\"date\"])\n",
        "\n",
        "    # Asset columns = everything except 'date' (preserve original order)\n",
        "    assets = [c for c in df.columns if c != \"date\"]\n",
        "    if len(assets) != 6:\n",
        "        print(f\"Warning: expected 6 assets, found {len(assets)}: {assets}\")\n",
        "\n",
        "    # Mean (expected) return for each asset across the 23 months\n",
        "    mu = df[assets].mean()\n",
        "\n",
        "    # Save TSV with headers exactly: asset, estimated_return\n",
        "    out = pd.DataFrame({\"asset\": assets, \"estimated_return\": [mu[a] for a in assets]})\n",
        "    out.to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(out)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjfnF-2Wtj6r"
      },
      "source": [
        "Submit \"estimated_returns.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTuIqrkAWXVL"
      },
      "source": [
        "## Part 4: Estimate Risk\n",
        "\n",
        "Estimate the covariance matrix for the asset returns to understand how the assets move together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RFZfIkTMxcv7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/estimated_covariance.tsv\n",
            "Preview:\n",
            "          AAPL       SPY      TSLA      AMZN      MSFT      NVDA\n",
            "                                                                \n",
            "AAPL  0.003627  0.000832  0.003255  0.000449  0.000389  0.000962\n",
            "SPY   0.000832  0.001292  0.002421  0.001666  0.001488  0.002840\n",
            "TSLA  0.003255  0.002421  0.026703  0.005571  0.002217 -0.000383\n",
            "AMZN  0.000449  0.001666  0.005571  0.004512  0.002875  0.003898\n",
            "MSFT  0.000389  0.001488  0.002217  0.002875  0.004044  0.004914\n",
            "NVDA  0.000962  0.002840 -0.000383  0.003898  0.004914  0.014523\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part04_estimate_covariance.py\n",
        "# Input : historical_returns.tsv  (date + 6 tickers, 23 rows)\n",
        "# Output: estimated_covariance.tsv (pandas-style covariance table, tab-separated)\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "IN_FILE  = \"historical_returns.tsv\"\n",
        "OUT_FILE = \"estimated_covariance.tsv\"\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(IN_FILE):\n",
        "        raise FileNotFoundError(f\"{IN_FILE} not found. Run Part 2 first.\")\n",
        "\n",
        "    # 1) Load monthly returns\n",
        "    df = pd.read_csv(IN_FILE, sep=\"\\t\", parse_dates=[\"date\"])\n",
        "\n",
        "    # 2) Asset columns (preserve original order)\n",
        "    assets = [c for c in df.columns if c != \"date\"]\n",
        "    if len(assets) != 6:\n",
        "        print(f\"Warning: expected 6 assets, found {len(assets)}: {assets}\")\n",
        "\n",
        "    # 3) Compute sample covariance (ddof=1)\n",
        "    returns = df[assets].dropna(how=\"any\")\n",
        "    Sigma = returns.cov(ddof=1)\n",
        "\n",
        "    # 4) Ensure blank top-left cell in header (as per pandas to_csv format)\n",
        "    Sigma.index.name = \"\"\n",
        "\n",
        "    # 5) Save TSV\n",
        "    Sigma.to_csv(OUT_FILE, sep=\"\\t\")\n",
        "\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(\"Preview:\")\n",
        "    print(Sigma)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOmn4s_yr5qn"
      },
      "source": [
        "Save the estimated covariances to a TSV file named \"estimated_covariance.tsv\".\n",
        "The header row should have a blank column name followed by the names of the assets.\n",
        "Each data row should start with the name of an asset for that row, and be followed by the individual covariances corresponding to that row and column's assets.\n",
        "(This is the format of pandas's `to_csv` method with `sep=\"\\t\"` when used on a covariance matrix as computed in the examples.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Te-NPQxSvuXm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/estimated_covariance.tsv\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part04_estimate_covariance.py\n",
        "# Input : historical_returns.tsv  (date + 6 tickers, 23 rows)\n",
        "# Output: estimated_covariance.tsv (TSV with blank top-left header)\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "IN_FILE  = \"historical_returns.tsv\"\n",
        "OUT_FILE = \"estimated_covariance.tsv\"\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(IN_FILE):\n",
        "        raise FileNotFoundError(f\"{IN_FILE} not found. Run Part 2 first.\")\n",
        "\n",
        "    # Load returns\n",
        "    df = pd.read_csv(IN_FILE, sep=\"\\t\", parse_dates=[\"date\"])\n",
        "\n",
        "    # Asset columns in original order\n",
        "    assets = [c for c in df.columns if c != \"date\"]\n",
        "\n",
        "    # Sample covariance (ddof=1) on returns\n",
        "    Sigma = df[assets].cov(ddof=1)\n",
        "\n",
        "    # Blank top-left header cell per spec\n",
        "    Sigma.index.name = \"\"\n",
        "\n",
        "    # Save TSV (pandas-style covariance table)\n",
        "    Sigma.to_csv(OUT_FILE, sep=\"\\t\")\n",
        "\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS9vek0btoK6"
      },
      "source": [
        "Submit \"estimated_covariance.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8rC5Eo3sEme"
      },
      "source": [
        "## Part 5: Construct the Maximum Return Portfolio\n",
        "\n",
        "Compute the maximum return portfolio based on your previously estimated risks and returns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "8LW0KKm-xb2I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/maximum_return.tsv\n",
            "  asset  allocation\n",
            "0  AAPL         0.0\n",
            "1   SPY         0.0\n",
            "2  TSLA         0.0\n",
            "3  AMZN         0.0\n",
            "4  MSFT         0.0\n",
            "5  NVDA         1.0\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part05_max_return.py\n",
        "# Input : estimated_returns.tsv  (asset, estimated_return)\n",
        "# Output: maximum_return.tsv     (asset, allocation) — long-only, sum to 1\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "RET_FILE = \"estimated_returns.tsv\"\n",
        "OUT_FILE = \"maximum_return.tsv\"\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(RET_FILE):\n",
        "        raise FileNotFoundError(f\"{RET_FILE} not found. Run Part 3 first.\")\n",
        "\n",
        "    # 1) Load estimated returns\n",
        "    er = pd.read_csv(RET_FILE, sep=\"\\t\")\n",
        "    if list(er.columns) != [\"asset\", \"estimated_return\"]:\n",
        "        raise ValueError(\"estimated_returns.tsv must have columns: 'asset', 'estimated_return'\")\n",
        "\n",
        "    assets = er[\"asset\"].tolist()\n",
        "    mu = pd.Series(er[\"estimated_return\"].values, index=assets)\n",
        "\n",
        "    # 2) Max-return allocation under long-only + budget=1\n",
        "    #    (All-in on argmax(mu); if there are ties, split evenly across the ties.)\n",
        "    tol = 1e-12\n",
        "    max_val = mu.max()\n",
        "    top = [a for a in assets if (max_val - mu[a]) <= tol]\n",
        "\n",
        "    alloc = pd.Series(0.0, index=assets)\n",
        "    alloc[top] = 1.0 / len(top)\n",
        "\n",
        "    # 3) Sanity: allocations sum to 1 and are non-negative\n",
        "    s = float(alloc.sum())\n",
        "    if abs(s - 1.0) > 1e-9:\n",
        "        alloc = alloc / s  # normalize just in case\n",
        "    if (alloc < -1e-12).any():\n",
        "        raise ValueError(\"Negative allocation encountered — check inputs.\")\n",
        "\n",
        "    # 4) Save TSV exactly as required\n",
        "    out = pd.DataFrame({\"asset\": assets, \"allocation\": [alloc[a] for a in assets]})\n",
        "    out.to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(out)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjPOxui5sLTD"
      },
      "source": [
        "Save the maximum return portfolio in a TSV file named \"maximum_return.tsv\".\n",
        "The header row should have two columns, \"asset\" and \"allocation\".\n",
        "The allocation values should sum up to one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xLl_j8z1vtiT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/maximum_return.tsv\n",
            "  asset  allocation\n",
            "0  AAPL         0.0\n",
            "1   SPY         0.0\n",
            "2  TSLA         0.0\n",
            "3  AMZN         0.0\n",
            "4  MSFT         0.0\n",
            "5  NVDA         1.0\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part05_max_return.py\n",
        "# Input : estimated_returns.tsv  (asset, estimated_return)\n",
        "# Output: maximum_return.tsv     (asset, allocation), allocations sum to 1\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "IN_FILE  = \"estimated_returns.tsv\"\n",
        "OUT_FILE = \"maximum_return.tsv\"\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(IN_FILE):\n",
        "        raise FileNotFoundError(f\"{IN_FILE} not found. Run Part 3 first.\")\n",
        "\n",
        "    # 1) Load estimated returns\n",
        "    df = pd.read_csv(IN_FILE, sep=\"\\t\")\n",
        "    if list(df.columns) != [\"asset\", \"estimated_return\"]:\n",
        "        raise ValueError(\"expected columns: 'asset', 'estimated_return'\")\n",
        "\n",
        "    assets = df[\"asset\"].tolist()\n",
        "    mu = pd.Series(df[\"estimated_return\"].values, index=assets)\n",
        "\n",
        "    # 2) Construct max-return portfolio (long-only, budget=1)\n",
        "    #    All weight on argmax; if ties, split evenly.\n",
        "    max_mu = mu.max()\n",
        "    tol = 1e-12\n",
        "    winners = [a for a in assets if (max_mu - mu[a]) <= tol]\n",
        "\n",
        "    alloc = pd.Series(0.0, index=assets, dtype=float)\n",
        "    alloc[winners] = 1.0 / len(winners)\n",
        "\n",
        "    # 3) Clean tiny numerical noise, ensure sum to 1\n",
        "    alloc = alloc.clip(lower=0)                 # no negatives\n",
        "    alloc = alloc / alloc.sum()                 # normalize exactly\n",
        "    alloc = alloc.round(15)                     # avoid -0.0, etc.\n",
        "\n",
        "    # 4) Save TSV: asset, allocation\n",
        "    out = pd.DataFrame({\"asset\": assets, \"allocation\": [alloc[a] for a in assets]})\n",
        "    out.to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(out)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bm3xrxptqJ2"
      },
      "source": [
        "Submit \"maximum_return.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_QxQ5NpsL-c"
      },
      "source": [
        "## Part 6: Construct the Minimum Risk Portfolio\n",
        "\n",
        "Compute the minimum risk portfolio based on your previously estimated risks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "daHSqhv9xbIF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/minimum_risk.tsv\n",
            "  asset    allocation\n",
            "0  AAPL  1.413660e-01\n",
            "1   SPY  8.586299e-01\n",
            "2  TSLA  3.845598e-06\n",
            "3  AMZN  2.093650e-07\n",
            "4  MSFT  0.000000e+00\n",
            "5  NVDA  0.000000e+00\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part06_min_risk.py\n",
        "# Input : estimated_covariance.tsv  (pandas-style covariance table)\n",
        "# Output: minimum_risk.tsv          (asset, allocation) — long-only, sum to 1\n",
        "\n",
        "# Requires: cvxpy (preferred) or scipy (fallback)\n",
        "# pip install cvxpy scipy pandas numpy\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "COV_FILE = \"estimated_covariance.tsv\"\n",
        "OUT_FILE = \"minimum_risk.tsv\"\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(COV_FILE):\n",
        "        raise FileNotFoundError(f\"{COV_FILE} not found. Run Part 4 first.\")\n",
        "\n",
        "    # 1) Load covariance matrix (assets as both index and columns)\n",
        "    Sigma = pd.read_csv(COV_FILE, sep=\"\\t\", index_col=0)\n",
        "    assets = list(Sigma.columns)\n",
        "    Sigma = Sigma.loc[assets, assets].astype(float)\n",
        "\n",
        "    # Symmetrize & add tiny ridge to avoid numerical issues (keeps solution the same to ~1e-10)\n",
        "    Sigma = 0.5 * (Sigma + Sigma.T)\n",
        "    Sigma += 1e-12 * np.eye(len(assets))\n",
        "\n",
        "    n = len(assets)\n",
        "    w_min = None\n",
        "\n",
        "    # 2) Solve min w^T Σ w  s.t. sum(w)=1, w>=0\n",
        "    try:\n",
        "        import cvxpy as cp\n",
        "        w = cp.Variable(n)\n",
        "        prob = cp.Problem(cp.Minimize(cp.quad_form(w, Sigma.values)),\n",
        "                          [cp.sum(w) == 1, w >= 0])\n",
        "        prob.solve(solver=cp.SCS, verbose=False)\n",
        "        if w.value is None:\n",
        "            raise RuntimeError(\"CVXPY solver failed to return a solution.\")\n",
        "        w_min = np.maximum(w.value, 0)\n",
        "    except Exception:\n",
        "        # SciPy fallback\n",
        "        from scipy.optimize import minimize\n",
        "        def var_obj(w): return float(w @ Sigma.values @ w)\n",
        "        bounds = [(0.0, 1.0)] * n\n",
        "        cons = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0},)\n",
        "        w0 = np.ones(n) / n\n",
        "        res = minimize(var_obj, w0, method=\"SLSQP\", bounds=bounds, constraints=cons, options={'maxiter': 1000})\n",
        "        if not res.success:\n",
        "            raise RuntimeError(f\"SciPy SLSQP failed: {res.message}\")\n",
        "        w_min = res.x\n",
        "\n",
        "    # 3) Clean & normalize\n",
        "    w_min = np.clip(w_min, 0, None)\n",
        "    s = w_min.sum()\n",
        "    if s <= 0:\n",
        "        raise RuntimeError(\"Degenerate solution (sum of weights <= 0).\")\n",
        "    w_min = (w_min / s).round(15)  # ensure sum=1 up to rounding\n",
        "\n",
        "    # 4) Save TSV: asset, allocation\n",
        "    out = pd.DataFrame({\"asset\": assets, \"allocation\": w_min})\n",
        "    out.to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(out)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzldkIPxsQor"
      },
      "source": [
        "Save the minimum risk portfolio in a TSV file named \"minimum_risk.tsv\".\n",
        "The header row should have two columns, \"asset\" and \"allocation\".\n",
        "The allocation values should sum up to one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "YRXccAflvrBZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/minimum_risk.tsv\n",
            "Sum of allocations: 1.000000000000\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part06_min_risk.py\n",
        "# Input : estimated_covariance.tsv  (pandas-style covariance table)\n",
        "# Output: minimum_risk.tsv          (asset, allocation) — long-only, sum to 1\n",
        "\n",
        "# Requires: cvxpy (preferred) or scipy (fallback)\n",
        "# pip install cvxpy scipy pandas numpy\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "IN_FILE  = \"estimated_covariance.tsv\"\n",
        "OUT_FILE = \"minimum_risk.tsv\"\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(IN_FILE):\n",
        "        raise FileNotFoundError(f\"{IN_FILE} not found. Run Part 4 first.\")\n",
        "\n",
        "    # Load covariance matrix (assets label rows/cols)\n",
        "    Sigma = pd.read_csv(IN_FILE, sep=\"\\t\", index_col=0).astype(float)\n",
        "    assets = list(Sigma.columns)\n",
        "    Sigma = Sigma.loc[assets, assets]\n",
        "    # Stabilize numerics\n",
        "    Sigma = 0.5 * (Sigma + Sigma.T)\n",
        "    Sigma += 1e-12 * np.eye(len(assets))\n",
        "\n",
        "    n = len(assets)\n",
        "    w_min = None\n",
        "\n",
        "    # Minimize w^T Σ w  s.t. sum(w)=1, w>=0\n",
        "    try:\n",
        "        import cvxpy as cp\n",
        "        w = cp.Variable(n)\n",
        "        prob = cp.Problem(cp.Minimize(cp.quad_form(w, Sigma.values)),\n",
        "                          [cp.sum(w) == 1, w >= 0])\n",
        "        prob.solve(solver=cp.SCS, verbose=False)\n",
        "        if w.value is None:\n",
        "            raise RuntimeError(\"CVXPY failed to return a solution.\")\n",
        "        w_min = np.maximum(w.value, 0)\n",
        "    except Exception:\n",
        "        from scipy.optimize import minimize\n",
        "        def var_obj(w): return float(w @ Sigma.values @ w)\n",
        "        bounds = [(0.0, 1.0)] * n\n",
        "        cons = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0},)\n",
        "        w0 = np.ones(n) / n\n",
        "        res = minimize(var_obj, w0, method=\"SLSQP\", bounds=bounds, constraints=cons, options={'maxiter': 1000})\n",
        "        if not res.success:\n",
        "            raise RuntimeError(f\"SciPy SLSQP failed: {res.message}\")\n",
        "        w_min = res.x\n",
        "\n",
        "    # Clean, normalize, and round\n",
        "    w_min = np.clip(w_min, 0, None)\n",
        "    w_min = w_min / w_min.sum()\n",
        "    w_min = np.round(w_min, 15)  # avoid -0.0, ensure clean sum\n",
        "\n",
        "    # Save TSV exactly as requested\n",
        "    pd.DataFrame({\"asset\": assets, \"allocation\": w_min}) \\\n",
        "      .to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(f\"Sum of allocations: {w_min.sum():.12f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5gy_XETtsoi"
      },
      "source": [
        "Submit \"minimum_risk.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzyJGWDvWhva"
      },
      "source": [
        "## Part 7: Build Efficient Frontier Portfolios\n",
        "\n",
        "Compute 101 portfolios along the mean-variance efficient frontier with evenly spaced estimated returns.\n",
        "The first portfolio should be the minimum risk portfolio from part 4, and the last portfolio should be the maximum return portfolio from part 3.\n",
        "The estimated return of each portfolio should be higher than the previous by one percent of the difference between the first and last portfolios.\n",
        "That is, the estimated return of the portfolios should be similar to `np.linspace(min_risk_return, max_return, 101)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "XaR6mKwvxZ4W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/efficient_frontier.tsv\n",
            "   index    return      risk      AAPL       SPY          TSLA          AMZN  \\\n",
            "0      0  0.019069  0.035033  0.141366  0.858630  3.845598e-06  2.093650e-07   \n",
            "1      1  0.019565  0.035378  0.105495  0.887477  9.225344e-07  1.804254e-07   \n",
            "2      2  0.020060  0.035810  0.107275  0.875424  4.865523e-06  9.328190e-07   \n",
            "3      3  0.020556  0.036265  0.109054  0.863372  9.657223e-06  1.842615e-06   \n",
            "4      4  0.021051  0.036743  0.110837  0.851312  8.581446e-06  1.646273e-06   \n",
            "\n",
            "   MSFT      NVDA  \n",
            "0   0.0  0.000000  \n",
            "1   0.0  0.007027  \n",
            "2   0.0  0.017296  \n",
            "3   0.0  0.027563  \n",
            "4   0.0  0.037841  \n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part07_efficient_frontier.py\n",
        "# Inputs:\n",
        "#   - estimated_returns.tsv     (asset, estimated_return)\n",
        "#   - estimated_covariance.tsv  (pandas-style covariance table, tab-separated)\n",
        "#   - minimum_risk.tsv          (asset, allocation)\n",
        "#   - maximum_return.tsv        (asset, allocation)\n",
        "# Output:\n",
        "#   - efficient_frontier.tsv    (index, return, risk, <asset columns>) — 101 rows, weights sum to 1\n",
        "#\n",
        "# Requires: cvxpy (preferred) or scipy (fallback)\n",
        "# pip install cvxpy scipy pandas numpy\n",
        "\n",
        "import os, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "RET_FILE   = \"estimated_returns.tsv\"\n",
        "COV_FILE   = \"estimated_covariance.tsv\"\n",
        "WMIN_FILE  = \"minimum_risk.tsv\"\n",
        "WMAX_FILE  = \"maximum_return.tsv\"\n",
        "OUT_FILE   = \"efficient_frontier.tsv\"\n",
        "\n",
        "def port_stats(w, mu, Sigma):\n",
        "    \"\"\"Return (mean, std) for weights w given mu (Series) and Sigma (DataFrame).\"\"\"\n",
        "    w = np.asarray(w, dtype=float)\n",
        "    mu_p = float(w @ mu.values)\n",
        "    var_p = float(w @ Sigma.values @ w)\n",
        "    sd_p  = math.sqrt(max(var_p, 0.0))\n",
        "    return mu_p, sd_p\n",
        "\n",
        "def main():\n",
        "    # --- Load inputs ---\n",
        "    if not all(os.path.exists(p) for p in [RET_FILE, COV_FILE, WMIN_FILE, WMAX_FILE]):\n",
        "        missing = [p for p in [RET_FILE, COV_FILE, WMIN_FILE, WMAX_FILE] if not os.path.exists(p)]\n",
        "        raise FileNotFoundError(f\"Missing inputs: {missing}. Run Parts 3, 4, 5, and 6 first.\")\n",
        "\n",
        "    mu = pd.read_csv(RET_FILE, sep=\"\\t\").set_index(\"asset\")[\"estimated_return\"]\n",
        "    Sigma = pd.read_csv(COV_FILE, sep=\"\\t\", index_col=0)\n",
        "    w_min = pd.read_csv(WMIN_FILE, sep=\"\\t\").set_index(\"asset\")[\"allocation\"]\n",
        "    w_max = pd.read_csv(WMAX_FILE, sep=\"\\t\").set_index(\"asset\")[\"allocation\"]\n",
        "\n",
        "    # Align assets (intersection, keep order from returns file)\n",
        "    assets = [a for a in mu.index if a in Sigma.columns and a in w_min.index and a in w_max.index]\n",
        "    if len(assets) < 2:\n",
        "        raise ValueError(\"Need at least two aligned assets to form a frontier.\")\n",
        "\n",
        "    mu    = mu.loc[assets]\n",
        "    Sigma = Sigma.loc[assets, assets].astype(float)\n",
        "    w_min = w_min.loc[assets].fillna(0.0)\n",
        "    w_max = w_max.loc[assets].fillna(0.0)\n",
        "\n",
        "    # Stabilize covariance for numeric safety\n",
        "    Sigma = 0.5 * (Sigma + Sigma.T)\n",
        "    Sigma += 1e-12 * np.eye(len(assets))\n",
        "\n",
        "    # Endpoints' returns\n",
        "    mu_min = float(w_min.values @ mu.values)\n",
        "    mu_max = float(w_max.values @ mu.values)\n",
        "    if mu_max < mu_min:\n",
        "        # swap if weird ordering (shouldn't happen, but let's be safe)\n",
        "        mu_min, mu_max = mu_max, mu_min\n",
        "        w_min, w_max = w_max, w_min\n",
        "\n",
        "    # 101 evenly spaced target returns\n",
        "    targets = np.linspace(mu_min, mu_max, 101)\n",
        "\n",
        "    # Try CVXPY first; else SciPy SLSQP\n",
        "    rows = []\n",
        "    n = len(assets)\n",
        "\n",
        "    try:\n",
        "        import cvxpy as cp\n",
        "        w = cp.Variable(n)\n",
        "        Sigma_np = Sigma.values\n",
        "        mu_np = mu.values\n",
        "        for i, t in enumerate(targets):\n",
        "            # Constraints: sum w = 1, w >= 0, w·μ >= t\n",
        "            cons = [cp.sum(w) == 1, w >= 0, w @ mu_np >= float(t)]\n",
        "            prob = cp.Problem(cp.Minimize(cp.quad_form(w, Sigma_np)), cons)\n",
        "            prob.solve(solver=cp.SCS, verbose=False)\n",
        "            w_sol = np.array(w.value, dtype=float).ravel()\n",
        "            # If solver struggles at extremes, project to feasible and renormalize\n",
        "            w_sol = np.maximum(w_sol, 0)\n",
        "            s = w_sol.sum()\n",
        "            if s <= 0:  # fallback to min-risk if infeasible\n",
        "                w_sol = w_min.values.copy()\n",
        "            else:\n",
        "                w_sol = w_sol / s\n",
        "\n",
        "            r, sdev = port_stats(w_sol, mu, Sigma)\n",
        "            row = {\"index\": i, \"return\": r, \"risk\": sdev}\n",
        "            row.update({a: w_sol[j] for j, a in enumerate(assets)})\n",
        "            rows.append(row)\n",
        "\n",
        "    except Exception:\n",
        "        from scipy.optimize import minimize\n",
        "\n",
        "        def var_obj(w): return float(w @ Sigma.values @ w)\n",
        "        bounds = [(0.0, 1.0)] * n\n",
        "        w0 = w_min.values.copy()\n",
        "\n",
        "        for i, t in enumerate(targets):\n",
        "            cons = (\n",
        "                {\"type\": \"eq\",   \"fun\": lambda w: np.sum(w) - 1.0},\n",
        "                {\"type\": \"ineq\", \"fun\": lambda w, t=t: (w @ mu.values) - float(t)},\n",
        "            )\n",
        "            res = minimize(var_obj, w0, method=\"SLSQP\", bounds=bounds, constraints=cons, options={\"maxiter\": 800})\n",
        "            if not res.success:\n",
        "                # If a target fails (usually very close to endpoints), back off to last good or endpoint\n",
        "                w_sol = w0.copy()\n",
        "            else:\n",
        "                w_sol = res.x\n",
        "            r, sdev = port_stats(w_sol, mu, Sigma)\n",
        "            row = {\"index\": i, \"return\": r, \"risk\": sdev}\n",
        "            row.update({a: w_sol[j] for j, a in enumerate(assets)})\n",
        "            rows.append(row)\n",
        "            w0 = w_sol\n",
        "\n",
        "    # Force endpoints to match exactly your provided min-risk and max-return portfolios\n",
        "    rows[0].update({\"return\": float(w_min.values @ mu.values),\n",
        "                    \"risk\":   math.sqrt(float(w_min.values @ Sigma.values @ w_min.values))})\n",
        "    for j, a in enumerate(assets):\n",
        "        rows[0][a] = float(w_min.values[j])\n",
        "\n",
        "    rows[-1].update({\"return\": float(w_max.values @ mu.values),\n",
        "                     \"risk\":   math.sqrt(float(w_max.values @ Sigma.values @ w_max.values))})\n",
        "    for j, a in enumerate(assets):\n",
        "        rows[-1][a] = float(w_max.values[j])\n",
        "\n",
        "    # Save output: index, return, risk, then asset columns\n",
        "    cols = [\"index\", \"return\", \"risk\"] + assets\n",
        "    df = pd.DataFrame(rows, columns=cols)\n",
        "\n",
        "    # Clean tiny numerical noise and ensure weights sum to 1\n",
        "    W = df[assets].to_numpy()\n",
        "    W = np.clip(W, 0, None)\n",
        "    sums = W.sum(axis=1, keepdims=True)\n",
        "    sums[sums == 0] = 1.0\n",
        "    W = W / sums\n",
        "    for k, a in enumerate(assets):\n",
        "        df[a] = np.round(W[:, k], 15)\n",
        "\n",
        "    df.to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(df.head())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e3WwTJvsDzh"
      },
      "source": [
        "Save the portfolios in a TSV file named \"efficient_frontier.tsv\".\n",
        "The header row should have columns \"index\", \"return\", \"risk\", and all the asset tickers.\n",
        "Each data row should have the portfolio index (0-100), the estimated return of the portfolio, the estimated standard deviation (not variance) of the portfolio, and all the asset allocations (which should sum to one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "e9DKadyNvniT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/efficient_frontier.tsv\n",
            "   index    return      risk      AAPL       SPY          TSLA          AMZN  \\\n",
            "0      0  0.019069  0.035033  0.141366  0.858630  3.845598e-06  2.093650e-07   \n",
            "1      1  0.019565  0.035378  0.105495  0.887477  9.225344e-07  1.804254e-07   \n",
            "2      2  0.020060  0.035810  0.107275  0.875424  4.865523e-06  9.328190e-07   \n",
            "3      3  0.020556  0.036265  0.109054  0.863372  9.657223e-06  1.842615e-06   \n",
            "4      4  0.021051  0.036743  0.110837  0.851312  8.581446e-06  1.646273e-06   \n",
            "\n",
            "   MSFT      NVDA  \n",
            "0   0.0  0.000000  \n",
            "1   0.0  0.007027  \n",
            "2   0.0  0.017296  \n",
            "3   0.0  0.027563  \n",
            "4   0.0  0.037841  \n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part07_efficient_frontier.py\n",
        "# Inputs:\n",
        "#   - estimated_returns.tsv     (asset, estimated_return)\n",
        "#   - estimated_covariance.tsv  (TSV covariance, blank top-left header)\n",
        "#   - minimum_risk.tsv          (asset, allocation)   # index 0 target\n",
        "#   - maximum_return.tsv        (asset, allocation)   # index 100 target\n",
        "# Output:\n",
        "#   - efficient_frontier.tsv    (index, return, risk, <asset columns>) — 101 rows\n",
        "\n",
        "# Requires: cvxpy (preferred) or scipy (fallback)\n",
        "# pip install cvxpy scipy pandas numpy\n",
        "\n",
        "import os, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "RET_FILE   = \"estimated_returns.tsv\"\n",
        "COV_FILE   = \"estimated_covariance.tsv\"\n",
        "WMIN_FILE  = \"minimum_risk.tsv\"\n",
        "WMAX_FILE  = \"maximum_return.tsv\"\n",
        "OUT_FILE   = \"efficient_frontier.tsv\"\n",
        "\n",
        "def port_stats(w, mu, Sigma):\n",
        "    w = np.asarray(w, float)\n",
        "    mu_p = float(w @ mu.values)\n",
        "    var_p = float(w @ Sigma.values @ w)\n",
        "    return mu_p, math.sqrt(max(var_p, 0.0))  # standard deviation\n",
        "\n",
        "def main():\n",
        "    # Load inputs\n",
        "    if not all(os.path.exists(p) for p in [RET_FILE, COV_FILE, WMIN_FILE, WMAX_FILE]):\n",
        "        missing = [p for p in [RET_FILE, COV_FILE, WMIN_FILE, WMAX_FILE] if not os.path.exists(p)]\n",
        "        raise FileNotFoundError(f\"Missing inputs: {missing}\")\n",
        "\n",
        "    mu = pd.read_csv(RET_FILE, sep=\"\\t\").set_index(\"asset\")[\"estimated_return\"]\n",
        "    Sigma = pd.read_csv(COV_FILE, sep=\"\\t\", index_col=0).astype(float)\n",
        "    w_min = pd.read_csv(WMIN_FILE, sep=\"\\t\").set_index(\"asset\")[\"allocation\"]\n",
        "    w_max = pd.read_csv(WMAX_FILE, sep=\"\\t\").set_index(\"asset\")[\"allocation\"]\n",
        "\n",
        "    # Align assets (keep order from estimated_returns.tsv)\n",
        "    assets = [a for a in mu.index if a in Sigma.columns and a in w_min.index and a in w_max.index]\n",
        "    if len(assets) < 2:\n",
        "        raise ValueError(\"Need at least two aligned assets.\")\n",
        "    mu, Sigma = mu.loc[assets], Sigma.loc[assets, assets]\n",
        "    w_min, w_max = w_min.loc[assets].fillna(0.0), w_max.loc[assets].fillna(0.0)\n",
        "\n",
        "    # Stabilize covariance\n",
        "    Sigma = 0.5*(Sigma + Sigma.T)\n",
        "    Sigma += 1e-12*np.eye(len(assets))\n",
        "\n",
        "    # Endpoints\n",
        "    mu_min = float(w_min.values @ mu.values)\n",
        "    mu_max = float(w_max.values @ mu.values)\n",
        "    if mu_max < mu_min:\n",
        "        mu_min, mu_max = mu_max, mu_min\n",
        "        w_min, w_max = w_max, w_min\n",
        "\n",
        "    targets = np.linspace(mu_min, mu_max, 101)\n",
        "\n",
        "    rows, n = [], len(assets)\n",
        "\n",
        "    # Solve with CVXPY if available, else SciPy\n",
        "    try:\n",
        "        import cvxpy as cp\n",
        "        w = cp.Variable(n)\n",
        "        S = Sigma.values\n",
        "        m = mu.values\n",
        "        for i, t in enumerate(targets):\n",
        "            cons = [cp.sum(w) == 1, w >= 0, w @ m >= float(t)]\n",
        "            cp.Problem(cp.Minimize(cp.quad_form(w, S)), cons).solve(solver=cp.SCS, verbose=False)\n",
        "            w_sol = np.maximum(np.array(w.value, float).ravel(), 0)\n",
        "            s = w_sol.sum()\n",
        "            w_sol = w_sol / s if s > 0 else w_min.values.copy()\n",
        "            r, sdev = port_stats(w_sol, mu, Sigma)\n",
        "            row = {\"index\": i, \"return\": r, \"risk\": sdev}\n",
        "            row.update({a: w_sol[j] for j,a in enumerate(assets)})\n",
        "            rows.append(row)\n",
        "    except Exception:\n",
        "        from scipy.optimize import minimize\n",
        "        def var_obj(x): return float(x @ Sigma.values @ x)\n",
        "        bnds = [(0.0, 1.0)]*n\n",
        "        w0 = w_min.values.copy()\n",
        "        for i, t in enumerate(targets):\n",
        "            cons = (\n",
        "                {\"type\": \"eq\",   \"fun\": lambda x: np.sum(x) - 1.0},\n",
        "                {\"type\": \"ineq\", \"fun\": lambda x, t=t: (x @ mu.values) - float(t)},\n",
        "            )\n",
        "            res = minimize(var_obj, w0, method=\"SLSQP\", bounds=bnds, constraints=cons, options={\"maxiter\": 800})\n",
        "            w_sol = res.x if res.success else w0.copy()\n",
        "            r, sdev = port_stats(w_sol, mu, Sigma)\n",
        "            row = {\"index\": i, \"return\": r, \"risk\": sdev}\n",
        "            row.update({a: w_sol[j] for j,a in enumerate(assets)})\n",
        "            rows.append(row)\n",
        "            w0 = w_sol\n",
        "\n",
        "    # Force endpoints to match exactly provided min-risk and max-return portfolios\n",
        "    rows[0][\"return\"] = float(w_min.values @ mu.values)\n",
        "    rows[0][\"risk\"]   = math.sqrt(float(w_min.values @ Sigma.values @ w_min.values))\n",
        "    for j,a in enumerate(assets): rows[0][a] = float(w_min.values[j])\n",
        "\n",
        "    rows[-1][\"return\"] = float(w_max.values @ mu.values)\n",
        "    rows[-1][\"risk\"]   = math.sqrt(float(w_max.values @ Sigma.values @ w_max.values))\n",
        "    for j,a in enumerate(assets): rows[-1][a] = float(w_max.values[j])\n",
        "\n",
        "    # Assemble dataframe and clean small numerical noise; ensure weights sum to 1\n",
        "    cols = [\"index\",\"return\",\"risk\"] + assets\n",
        "    df = pd.DataFrame(rows, columns=cols)\n",
        "    W = df[assets].to_numpy()\n",
        "    W = np.clip(W, 0, None)\n",
        "    sums = W.sum(axis=1, keepdims=True)\n",
        "    sums[sums == 0] = 1.0\n",
        "    W = W / sums\n",
        "    for k,a in enumerate(assets):\n",
        "        df[a] = np.round(W[:,k], 15)\n",
        "\n",
        "    # Save TSV with required header and rows\n",
        "    df.to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(df.head())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiOa06rItvbs"
      },
      "source": [
        "Submit \"efficient_frontier.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoW0XBXAzzR6"
      },
      "source": [
        "## Part 8: Check Maximum Return Portfolio Stability\n",
        "\n",
        "Check the stability of the maximum return portfolio by resampling the estimated risk/return model.\n",
        "\n",
        "Repeat 1000 times -\n",
        "1. Use `np.random.multivariate_normal` to generate 23 return samples using your previously estimated risks and returns.\n",
        "2. Estimate the return of each asset using that resampled return history.\n",
        "3. Check which asset had the highest return in those resampled estimates.\n",
        "\n",
        "This procedure is a reduced and simplified version of the Michaud resampled efficient frontier procedure that takes uncertainty in the risk model into account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Xfke5V57xYvT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/max_return_probabilities.tsv\n",
            "  asset  probability\n",
            "5  NVDA        0.843\n",
            "2  TSLA        0.145\n",
            "0  AAPL        0.006\n",
            "3  AMZN        0.005\n",
            "1   SPY        0.001\n",
            "4  MSFT        0.000\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part08_max_return_stability.py\n",
        "# Inputs :\n",
        "#   - estimated_returns.tsv     (asset, estimated_return)\n",
        "#   - estimated_covariance.tsv  (pandas-style covariance table)\n",
        "#   - historical_returns.tsv    (optional; used only to infer T=number of months)\n",
        "# Output :\n",
        "#   - max_return_probabilities.tsv  (asset, probability)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "RET_FILE   = \"estimated_returns.tsv\"\n",
        "COV_FILE   = \"estimated_covariance.tsv\"\n",
        "RET_HIST   = \"historical_returns.tsv\"  # optional, to infer T\n",
        "OUT_FILE   = \"max_return_probabilities.tsv\"\n",
        "\n",
        "N_TRIALS = 1000  # per spec\n",
        "SEED     = 17    # reproducibility\n",
        "\n",
        "def make_psd(S):\n",
        "    \"\"\"Project symmetric matrix to nearest PSD by zeroing negative eigenvalues.\"\"\"\n",
        "    # Ensure symmetry\n",
        "    S = 0.5 * (S + S.T)\n",
        "    vals, vecs = np.linalg.eigh(S)\n",
        "    vals_clipped = np.clip(vals, a_min=0.0, a_max=None)\n",
        "    S_psd = (vecs * vals_clipped) @ vecs.T\n",
        "    # Tiny ridge for numerical stability\n",
        "    S_psd += 1e-12 * np.eye(S_psd.shape[0])\n",
        "    return S_psd\n",
        "\n",
        "def main():\n",
        "    # --- Load estimated returns and covariance ---\n",
        "    if not os.path.exists(RET_FILE) or not os.path.exists(COV_FILE):\n",
        "        missing = [p for p in [RET_FILE, COV_FILE] if not os.path.exists(p)]\n",
        "        raise FileNotFoundError(f\"Missing input(s): {missing}. Run Parts 3 and 4 first.\")\n",
        "\n",
        "    mu = pd.read_csv(RET_FILE, sep=\"\\t\").set_index(\"asset\")[\"estimated_return\"]\n",
        "    Sigma = pd.read_csv(COV_FILE, sep=\"\\t\", index_col=0)\n",
        "\n",
        "    # Align assets (intersection; keep order from mu file)\n",
        "    assets = [a for a in mu.index if a in Sigma.columns]\n",
        "    if len(assets) < 2:\n",
        "        raise ValueError(\"Need at least two aligned assets.\")\n",
        "    mu = mu.loc[assets].astype(float)\n",
        "    Sigma = Sigma.loc[assets, assets].astype(float)\n",
        "\n",
        "    # In-sample length T: read from historical_returns if available, else use 23\n",
        "    if os.path.exists(RET_HIST):\n",
        "        T = pd.read_csv(RET_HIST, sep=\"\\t\", parse_dates=[\"date\"]).shape[0]\n",
        "    else:\n",
        "        T = 23  # 24 months of prices -> 23 monthly returns (per spec)\n",
        "\n",
        "    # Ensure PSD covariance for sampling\n",
        "    Sigma_psd = make_psd(Sigma.to_numpy())\n",
        "\n",
        "    # --- Resampling loop ---\n",
        "    rng = np.random.default_rng(SEED)\n",
        "    counts = dict.fromkeys(assets, 0)\n",
        "\n",
        "    for _ in range(N_TRIALS):\n",
        "        # Draw T samples of returns ~ N(mu, Sigma)\n",
        "        sample = rng.multivariate_normal(mean=mu.values, cov=Sigma_psd, size=T)  # shape (T, n)\n",
        "        # Re-estimate mean returns from the sample\n",
        "        mu_hat = sample.mean(axis=0)  # shape (n,)\n",
        "        # Identify the highest-return asset this trial\n",
        "        winner_idx = int(np.argmax(mu_hat))\n",
        "        counts[assets[winner_idx]] += 1\n",
        "\n",
        "    # Convert counts -> probabilities\n",
        "    probs = pd.DataFrame({\n",
        "        \"asset\": assets,\n",
        "        \"probability\": [counts[a] / N_TRIALS for a in assets]\n",
        "    })\n",
        "\n",
        "    # Save TSV exactly as requested\n",
        "    probs.to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(probs.sort_values(\"probability\", ascending=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fes_ScDyz0jp"
      },
      "source": [
        "Save a file \"max_return_probabilities.tsv\" with the distribution of highest return assets.\n",
        "The header row should have columns \"asset\" and \"probability\".\n",
        "There should be a data row for each asset and its sample probability of having the highest return based on those 1000 resampled estimates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ZAjr15ASvj1S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/max_return_probabilities.tsv\n",
            "  asset  probability\n",
            "5  NVDA        0.843\n",
            "2  TSLA        0.145\n",
            "0  AAPL        0.006\n",
            "3  AMZN        0.005\n",
            "1   SPY        0.001\n",
            "4  MSFT        0.000\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# part08_max_return_stability.py\n",
        "# Inputs:\n",
        "#   - estimated_returns.tsv     (asset, estimated_return)\n",
        "#   - estimated_covariance.tsv  (pandas-style covariance table)\n",
        "#   - historical_returns.tsv    (optional; used to infer T=number of months)\n",
        "# Output:\n",
        "#   - max_return_probabilities.tsv (asset, probability)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "RET_FILE = \"estimated_returns.tsv\"\n",
        "COV_FILE = \"estimated_covariance.tsv\"\n",
        "RET_HIST = \"historical_returns.tsv\"  # optional to infer T\n",
        "OUT_FILE = \"max_return_probabilities.tsv\"\n",
        "\n",
        "N_TRIALS = 1000\n",
        "SEED = 17  # reproducible\n",
        "\n",
        "def make_psd(S):\n",
        "    S = 0.5 * (S + S.T)\n",
        "    vals, vecs = np.linalg.eigh(S)\n",
        "    vals = np.clip(vals, 0.0, None)\n",
        "    S_psd = (vecs * vals) @ vecs.T\n",
        "    S_psd += 1e-12 * np.eye(S_psd.shape[0])\n",
        "    return S_psd\n",
        "\n",
        "def main():\n",
        "    if not os.path.exists(RET_FILE) or not os.path.exists(COV_FILE):\n",
        "        missing = [p for p in [RET_FILE, COV_FILE] if not os.path.exists(p)]\n",
        "        raise FileNotFoundError(f\"Missing input(s): {missing}. Run Parts 3 and 4 first.\")\n",
        "\n",
        "    mu = pd.read_csv(RET_FILE, sep=\"\\t\").set_index(\"asset\")[\"estimated_return\"].astype(float)\n",
        "    Sigma = pd.read_csv(COV_FILE, sep=\"\\t\", index_col=0).astype(float)\n",
        "\n",
        "    # Align assets (keep order from estimated_returns.tsv)\n",
        "    assets = [a for a in mu.index if a in Sigma.columns]\n",
        "    mu = mu.loc[assets]\n",
        "    Sigma = Sigma.loc[assets, assets]\n",
        "\n",
        "    # Infer T (# of monthly returns)\n",
        "    if os.path.exists(RET_HIST):\n",
        "        T = pd.read_csv(RET_HIST, sep=\"\\t\", parse_dates=[\"date\"]).shape[0]\n",
        "    else:\n",
        "        T = 23  # 24 months of prices -> 23 returns\n",
        "\n",
        "    Sigma_psd = make_psd(Sigma.to_numpy())\n",
        "    rng = np.random.default_rng(SEED)\n",
        "\n",
        "    counts = dict.fromkeys(assets, 0)\n",
        "    for _ in range(N_TRIALS):\n",
        "        sample = rng.multivariate_normal(mean=mu.values, cov=Sigma_psd, size=T)  # (T, n)\n",
        "        mu_hat = sample.mean(axis=0)\n",
        "        winner = assets[int(np.argmax(mu_hat))]\n",
        "        counts[winner] += 1\n",
        "\n",
        "    probs = pd.DataFrame({\n",
        "        \"asset\": assets,\n",
        "        \"probability\": [counts[a] / N_TRIALS for a in assets]\n",
        "    })\n",
        "    probs.to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "    print(probs.sort_values(\"probability\", ascending=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xd34FQ6txoj"
      },
      "source": [
        "Submit \"max_return_probabilities.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYbJ21qUYvL_"
      },
      "source": [
        "## Part 9: Acknowledgments\n",
        "\n",
        "Make a file \"acknowledgments.txt\" documenting any outside sources or help on this project.\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for.\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy.\n",
        "If no acknowledgements are appropriate, just write none in the file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote: /workspaces/dx704-project-01/acknowledgments.txt\n"
          ]
        }
      ],
      "source": [
        "# part09_acknowledgments.py\n",
        "# Output: acknowledgments.txt\n",
        "\n",
        "import os\n",
        "OUT_FILE = \"acknowledgments.txt\"\n",
        "\n",
        "# Set to True if you want the file to contain just \"none\"\n",
        "WRITE_NONE = False\n",
        "\n",
        "TEMPLATE = \"\"\"Acknowledgments\n",
        "---------------\n",
        "\n",
        "\n",
        "\n",
        "Libraries used (brief purpose):\n",
        "- pandas — data manipulation and TSV I/O\n",
        "- numpy — numeric operations\n",
        "- yfinance — downloading historical prices from Yahoo Finance\n",
        "- cvxpy — quadratic programming (min-variance & frontier)\n",
        "- scipy.optimize — SLSQP fallback optimizer\n",
        "(Keep/edit as needed to reflect what you actually used.)\n",
        "\n",
        "Generative AI usage (per course policy):\n",
        "- Tool: ChatGPT (used for code scaffolding and clarification).\n",
        "- I reviewed, executed, and verified all code and results.\n",
        "- Transcript links:\n",
        "\n",
        "Course-provided resources consulted:\n",
        "- https://github.com/bu-cds-dx704/dx704-project-01\n",
        "- https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def main():\n",
        "    content = \"none\\n\" if WRITE_NONE else TEMPLATE\n",
        "    with open(OUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(content)\n",
        "    print(f\"Wrote: {os.path.abspath(OUT_FILE)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3oWYYHlt42V"
      },
      "source": [
        "Submit \"acknowledgements.txt\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8FWiTjvwscA"
      },
      "source": [
        "## Part 10: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n",
        "You do not need to provide code for data collection if you did that by manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.3.1)\n",
            "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (2.3.1)\n",
            "Requirement already satisfied: cvxpy in /opt/conda/lib/python3.12/site-packages (1.7.2)\n",
            "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (1.16.0)\n",
            "Requirement already satisfied: yfinance in /opt/conda/lib/python3.12/site-packages (0.2.65)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /opt/conda/lib/python3.12/site-packages (from cvxpy) (1.0.4)\n",
            "Requirement already satisfied: clarabel>=0.5.0 in /opt/conda/lib/python3.12/site-packages (from cvxpy) (0.11.1)\n",
            "Requirement already satisfied: scs>=3.2.4.post1 in /opt/conda/lib/python3.12/site-packages (from cvxpy) (3.2.8)\n",
            "Requirement already satisfied: requests>=2.31 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /opt/conda/lib/python3.12/site-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /opt/conda/lib/python3.12/site-packages (from yfinance) (2.4.2)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /opt/conda/lib/python3.12/site-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /opt/conda/lib/python3.12/site-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from yfinance) (6.32.0)\n",
            "Requirement already satisfied: websockets>=13.0 in /opt/conda/lib/python3.12/site-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
            "Requirement already satisfied: cffi in /home/codespace/.local/lib/python3.12/site-packages (from clarabel>=0.5.0->cvxpy) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /home/codespace/.local/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (2025.7.9)\n",
            "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi->clarabel>=0.5.0->cvxpy) (2.22)\n",
            "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from osqp>=0.6.2->cvxpy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from osqp>=0.6.2->cvxpy) (80.9.0)\n",
            "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from osqp>=0.6.2->cvxpy) (1.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->osqp>=0.6.2->cvxpy) (3.0.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas numpy cvxpy scipy yfinance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDEYI-K8vcUW"
      },
      "source": [
        "Submit \"project.ipynb\" in Gradescope."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
